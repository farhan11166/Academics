{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fb25b6-5271-4a53-95e5-2d54584a3448",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import faiss\n",
    "import time \n",
    "from dotenv import load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4f42cb",
   "metadata": {},
   "source": [
    "1.Loading the csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9dbc3db-78d6-4f0b-9cd9-80ba1bb6df0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('farhan11166/project/Documents/test csv/health_activity_data.csv')\n",
    "df.columns = df.columns.str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a18cc0",
   "metadata": {},
   "source": [
    "2.Preparing the rag model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f75199c-35c8-47e6-b5ba-7c29f7e91cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('pandas_queries (1) (1).csv')\n",
    "data.columns=['query','pandas_function_call']        \n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "queries=[i for i in data['query']]\n",
    "embeddings = model.encode(queries, convert_to_numpy=True)\n",
    "embedding_dim = embeddings.shape[1]\n",
    "index = faiss.IndexFlatL2(embedding_dim)\n",
    "index.add(embeddings)\n",
    "function_calls = [i for i in data['pandas_function_call']]\n",
    "def retrieve_similar_queries(user_query, k=3):\n",
    "    query_embedding = model.encode([user_query], convert_to_numpy=True)\n",
    "    distances, indices = index.search(query_embedding, k)\n",
    "    results = [(queries[i], function_calls[i]) for i in indices[0]]\n",
    "    return results\n",
    "def rag_pipeline(user_query):\n",
    "    examples = retrieve_similar_queries(user_query)\n",
    "    prompt = build_prompt(user_query, examples)\n",
    "    result = query_grok_ai(prompt)\n",
    "    return result    \n",
    "def build_prompt(user_query, examples):\n",
    "    prompt = \"\"\"\n",
    "You are an assistant that translates natural language into pandas code.\n",
    "Use the examples to understand the pattern and write the correct function.\n",
    "Return only the function in case of multiple function being availaible return onyl one of those.If two sperate functions are given instead of , use space.\n",
    "Examples:\n",
    "\"\"\"\n",
    "    for q, a in examples:\n",
    "        prompt += f\"Q: {q}\\nA: {a}\\n\\n\"\n",
    "    prompt += f\"Now answer this:\\nQ: {user_query}\\nA:\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c997456d",
   "metadata": {},
   "source": [
    "3.Methods for calling the API and returning valid uses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e7cda8a8-00af-4843-be59-0f8bfbedeb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from fastapi import FastAPI, UploadFile, Form\n",
    "from fastapi.responses import JSONResponse\n",
    "import pandas as pd\n",
    "import io\n",
    "import requests\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "GROQ_API_KEY = os.getenv(\"API_KEY\")\n",
    "GROQ_URL = \"https://api.groq.com/openai/v1/chat/completions\"\n",
    "MODEL = \"meta-llama/llama-4-scout-17b-16e-instruct\" \n",
    "\n",
    "chat_history = [\n",
    "    {\"role\": \"system\", \"content\":'''I have been given a csv file i will give you prompt regarding that data and then you must just return the \n",
    "    function to be used nothing else assume that the column exists else that the function is possible \n",
    "    dont give code just the function to be used for example if asked that what is total money spent return df['money'].sum() .Do not give functions in or give\n",
    "    only one of in case .Do not give alternative functions give only one in case it can be done in multiple ways if choice is given between a more than 1 step function\n",
    "    and a 1 step function always prefer one step function pass/Do not give alternative functions give only one incase mpre than one options are availaible.while using columnname match from one of columns present  '''}\n",
    "]\n",
    "column_info = f\"The DataFrame contains the following columns: {', '.join(df.columns)}\"\n",
    "chat_history[0][\"content\"] += \"\\n\\n\" + column_info\n",
    "first_five_rows = df.head(5)\n",
    "data_summary = first_five_rows.to_json(orient='records')\n",
    "chat_history.append({\"role\":\"system\",\"content\":f\"Here are the first five rows of my data: {data_summary}.\"})\n",
    "datap=[]\n",
    "def chat_with_groq(user_message,user_input):\n",
    "    chat_history.append({\"role\": \"user\", \"content\": user_message})\n",
    "    \n",
    "\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {GROQ_API_KEY}\"\n",
    "    }\n",
    "\n",
    "    data = {\n",
    "        \"model\": MODEL,\n",
    "        \"messages\": chat_history\n",
    "    }\n",
    "\n",
    "    response = requests.post(GROQ_URL, headers=headers, json=data)\n",
    "    response.raise_for_status()\n",
    "    bot_message = response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "    chat_history.append({\"role\": \"assistant\", \"content\": bot_message})\n",
    "    datap.append({\"query\":user_input,\"pandas_function_call\":bot_message})\n",
    "    return bot_message\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b6c4fd",
   "metadata": {},
   "source": [
    "4.Calling api returning functions for data and query and then generating the output on pc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adaeaba8-a545-4f3b-9fb3-09b3c20640c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You:  calculate correlation of height and weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df[['height_cm', 'weight_kg']].corr().iloc[0,1]\n",
      "-0.05037718176212504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You:   calculate correlation of height and weight in women\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df[df['gender'] == 'Female'][['height_cm', 'weight_kg']].corr().iloc[0,1]\n",
      "-0.09145422851594309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You:  calculate correlation of height and weight in men\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df[df['gender'] == 'Male'][['height_cm', 'weight_kg']].corr().iloc[0,1]\n",
      "-0.01441903599585993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You:  calculate correlation of diabetice people and wieght\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df[df['diabetic'] == 'Yes'][['weight_kg']].std()\n",
      "weight_kg    19.271587\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You:  exit\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    \n",
    "    if user_input.lower() in [\"exit\", \"quit\"]:\n",
    "        break\n",
    "    examples = retrieve_similar_queries(user_input)\n",
    "    prompt = build_prompt(user_input, examples)\n",
    "    response = chat_with_groq(prompt,user_input)\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        l = [line.strip() for line in response.split(\";\")]\n",
    "       \n",
    "        l=l[len(l)-1]\n",
    "       \n",
    "        print(l)\n",
    "        \n",
    "        \n",
    "        \n",
    "        if \"df\" in l:\n",
    "            alu=eval(response, {\"__builtins__\": {}}, {\"df\": df})\n",
    "            print(alu)\n",
    "            plt.show()\n",
    "    except KeyError as e:\n",
    "        print(f\"❌ KeyError: Column {str(e)} does not exist.\")\n",
    "        datap.pop(len(datap)-1)\n",
    "    except TypeError as e:\n",
    "        print(f\"❌ TypeError: {str(e)}\")\n",
    "        datap.pop(len(datap)-1)   \n",
    "    except ValueError as e:\n",
    "        print(f\"❌ ValueError: {str(e)}\")\n",
    "        datap.pop(len(datap)-1)\n",
    "    except AttributeError as e:\n",
    "        print(f\"❌ AttributeError: {str(e)}\")\n",
    "        datap.pop(len(datap)-1)\n",
    "    except SyntaxError as e:\n",
    "        print(f\"❌ SyntaxError: {str(e)}   {response}\")\n",
    "        datap.pop(len(datap)-1)\n",
    "    except NameError as e:\n",
    "        print(f\"❌ NameError: {str(e)}\")\n",
    "        datap.pop(len(datap)-1)\n",
    "        \n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Unexpected Error: {str(e)}\")\n",
    "        datap.pop(len(datap)-1)\n",
    "    time.sleep(1)    \n",
    "      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c2ddaf",
   "metadata": {},
   "source": [
    "5.Saving it in the data used for rag model hence improving the odel for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a884cef7-3384-47ff-a903-3186c46d1b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "fer=pd.DataFrame(datap)\n",
    "filep='pandas_queries (1) (1).csv'\n",
    "write_header = not os.path.exists(filep)\n",
    "\n",
    "fer.to_csv(filep, mode='a', index=False, header=write_header)\n",
    "data=pd.read_csv('pandas_queries (1) (1).csv')\n",
    "final=data.drop_duplicates()\n",
    "final.to_csv(filep,index=False,header=write_header)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
